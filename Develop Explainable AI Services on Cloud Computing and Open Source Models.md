# Develop Explainable AI Services on Cloud Computing and Open Source Models

## Presenters
- Zerui Wang, Ph.D. candidate, Department of Electrical and Computer Engineering, Concordia University
- Dr. Yan Liu, Full Professor and Gina Cody Research and Innovation Fellow, Concordia University

## Date and Time
Wednesday, November 13, 2024

 10:00 AM - 12:30 PM (2.5 hours)

## Abstract
This tutorial introduces systematic methods with supplementary tools and computing models for developing explainable AI (XAI). As AI increasingly penetrates various application domains, practitioners need more comprehensive approaches for model quality assessments and explainability. We bridge the gap between theoretical XAI techniques and their practical implementation in cloud services and open-source models, exploring a range of XAI methodologies and their applicability across diverse AI models and deployment scenarios.

## Tutorial Goals
1. Provide an understanding of state-of-the-art XAI methods and their theoretical foundations
2. Demonstrate practical implementation of XAI techniques for both cloud services and open-source models
3. Explore strategies for integrating XAI into the MLOps lifecycle
4. Analyze computational costs and performance implications of XAI in production environments
5. Investigate the robustness of XAI methods under adversarial conditions

## Detailed Program

### Segment 1: Theoretical Foundations (45 minutes)
- Introduction to XAI
  - Definition of XAI
  - Current challenges in AI transparency
- AI Quality Requirements and the Role of XAI
  - Quality concerns in cloud AI services
  - How XAI addresses these concerns
- Challenges of XAI
  - Operational complexity in adapting XAI to diverse models
  - Balancing explainability with model performance
- XAI Tools and Frameworks
  - Overview of existing XAI frameworks
  - Comparison of strengths and limitations

### Segment 2: XAI Service Operation (45 minutes)
- Essential Components
  - Data Processing Microservice
  - AI Model Microservice
  - XAI Method Microservice
  - Evaluation Microservice
- Parallel XAI Pipelines
  - Efficient processing of multiple XAI tasks
  - Reducing computation time for complex AI systems
- Deployment and CLI Operations
  - Streamlined deployment process
  - Comprehensive CLI for configuring and executing XAI tasks
  - Containerization for scaling and cross-platform compatibility

### Segment 3: XAI Application Scenarios and Future Directions (45 minutes)
- Cloud AI Service Evaluation and Discoveries
  - Integration with Azure AI services
  - Uncovering inconsistencies in model predictions across platforms
- Adversary Perturbation for Open Model AI Services
  - Experiments with various adversarial perturbations
  - Robustness analysis of vision models
- Hands on demonstration with the Colab notebook.
  - Tabular and Vision models.
  - SHAP, LIME, and GradCAM methods test implementation.


### Q&A and Discussion (15 minutes)
- Open forum for questions and interactive discussion

## Target Audience
- AI/ML Researchers: Those looking to expand their knowledge of XAI techniques and their practical implementation
- Data Scientists and Machine Learning Engineers: Professionals working on developing interpretable and transparent AI systems
- Software Developers: Those interested in integrating XAI capabilities into existing AI applications or services
- Cloud Computing Professionals: Individuals seeking to enhance the explainability of AI services deployed on cloud platforms

This tutorial is designed to accommodate participants with varying levels of expertise, from beginners to advanced practitioners in the field of AI and XAI.

## Materials
Participants will receive:
- Access to presentation slides
- Access to the open-source XAI framework
- Code samples for hands-on exercise
- List of recommended readings and tools

## Special Requirements
- Participants are encouraged to bring their own laptops for hands-on sessions
- CUDA-enabled GPU are required for local model inferencing
- A stable internet connection is required for cloud-based demonstrations
- Pre-training time is required by cloud AI service provider.

## Relevance to CASCON
This tutorial on "Develop Explainable AI Services on Cloud Computing and Open Source Models" aligns closely with CASCON's mission as a premier conference bridging academia and industry in computer science and software engineering. By addressing the challenge of AI explainability, it caters to the diverse CASCON audience of researchers, innovators, and practitioners. The tutorial combines research with practical implementation strategies, reflecting CASCON's focus on advanced studies and real-world applications. It contributes to the conference's tradition of knowledge sharing and innovation by exploring the intersection of AI, cloud computing, and software engineering. 